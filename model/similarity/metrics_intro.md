# 基于Token的查重指标介绍

---

### 1. 杰卡德相似度 (Jaccard Similarity)

**核心思想：**

把两份代码看作两个“词袋”（Bag of Words），杰卡德相似度衡量的是这两个词袋的重合程度。它不关心词语（Token）出现的顺序和频率，只关心“有哪些词语出现过”。

**计算对象：**

两个Token集合 (Python `set`)。

**计算公式：**
$$
\text{Jaccard}(A, B) = \frac{|A \cap B|}{|A \cup B|}
$$
- $|A \cap B|$：两份代码中**共同出现过**的独立Token的数量。
- $|A \cup B|$：两份代码中**所有出现过**的独立Token的总数量。

**擅长检测的场景：**
- **代码块乱序**：当学生将函数、类的定义顺序打乱，或者将代码块从一个地方挪到另一个地方时，Jaccard指数基本不受影响。
- **词汇借用**：能有效发现两份代码是否使用了大量相同的“词汇”（变量名、函数名、常量等），即使它们的用法和顺序完全不同。

**局限性：**

完全忽略了代码的逻辑顺序。例如，`a = b + c` 和 `b = a + c` 在它看来可能非常相似。

**给用户的UI简介：**
> **词汇重合度 (Jaccard Similarity)**：衡量两份代码使用了多少相同的“词汇”（如变量名、函数名等），不考虑代码顺序。此指标越高，说明两份代码的“用词”越相似。

---

### 2. 最长公共子序列比率 (LCS Ratio)

**核心思想：**

寻找两段Token序列中，按顺序排列的、最长的共同部分（Longest Common Subsequence）。这个指标非常重视代码的原始逻辑顺序。

**计算对象：**

两个Token列表 (Python `list`)。

**计算公式：**
$$
\text{LCS Ratio}(A, B) = \frac{2 \times \text{Length}(\text{LCS}(A, B))}{\text{Length}(A) + \text{Length}(B)}
$$
- $\text{LCS}(A, B)$：A和B的最长公共子序列。
- $\text{Length}(\cdot)$：序列的长度。

**擅长检测的场景：**
- **直接复制粘贴**：对于大段的连续代码复制，LCS能非常准确地捕捉到。
- **插入式修改**：即便抄袭者在复制的代码中间插入了一些自己的“干扰”代码，LCS依然能跳过这些干扰，找到前后连接起来的公共部分。

**局限性：**

对代码块的顺序调换非常敏感。如果将一个函数从文件末尾移到开头，LCS比率会显著下降。

**给用户的UI简介：**
> **逻辑顺序相似度 (LCS Ratio)**：衡量两份代码是否存在大量逻辑顺序相同的代码片段。此指标越高，说明一份代码很可能是从另一份直接复制并稍加修改得来的。

---

### 3. Levenshtein 距离 (编辑距离)

**核心思想：**

计算将一个Token序列变成另一个Token序列所需的最少“编辑”操作（插入、删除、替换）次数。距离越小，说明序列越相似。

**计算对象：**
两个Token列表 (Python `list`)。

**计算公式（相似度）：**
$$
\text{Levenshtein Ratio}(A, B) = 1 - \frac{\text{LevenshteinDistance}(A, B)}{\max(\text{Length}(A), \text{Length}(B))}
$$

**擅长检测的场景：**
- **细微修改**：能精确捕捉到诸如修改操作符（`+`改成`-`）、替换某个函数调用等细微差别。
- **综合性度量**：它同时考虑了顺序和内容，是一个非常全面的文本相似度指标。我们之前在字符串上使用的 `difflib.SequenceMatcher` 的 `ratio()` 方法，其底层算法就与此非常相似。

**局限性：**

计算开销相对较大。

**给用户的UI简介：**
> **编辑距离相似度 (Levenshtein Ratio)**：衡量将一份代码“变”成另一份代码需要多少步骤。此指标越高，说明两份代码在内容和顺序上都非常接近，只需少量改动即可互相转换。

### 4. 序列匹配度 (Sequence Match Ratio)

**核心思想：**

基于 `difflib.SequenceMatcher` 库，采用 Ratcliff/Obershelp 模式匹配算法。它通过递归地寻找两个序列中最长的、连续的、完全匹配的子块来工作，衡量的是两个序列中相同部分所占的比例。

**计算对象：**

两个Token列表 (Python `list`)。

**计算逻辑：**
1. 在序列A和B中找到最长的一个公共子块。
2. 在这个公共子块的左右两边，对剩余的部分递归地重复步骤1。
3. 将所有找到的公共子块的长度相加，得到总匹配长度 M。
4. 最终比率通过公式 `2 * M / T` 计算，其中 T 是两个序列的总长度。

**擅长检测的场景：**
- **连续代码块的匹配**：对大段未作修改的复制粘贴非常敏感。
- **效率较高**：相比于编辑距离的纯动态规划，`SequenceMatcher` 在处理长序列时通常更快。

**局限性**

对零散、细碎的修改不如编辑距离敏感。

**给用户的UI简介：**
> **序列匹配度 (SeqMatch)**：通过寻找两份代码中最长的连续匹配块，并递归地处理剩余部分，来计算总体的匹配程度。此指标越高，说明两份代码中可以找到的相同代码片段越多、越长。