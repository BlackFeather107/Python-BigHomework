# 基于Token的查重指标介绍

---

### 1. 杰卡德相似度 (Jaccard Similarity)

**核心思想：**

把两份代码看作两个“词袋”（Bag of Words），杰卡德相似度衡量的是这两个词袋的重合程度。它不关心词语（Token）出现的顺序和频率，只关心“有哪些词语出现过”。

**计算对象：**

两个Token集合 (Python `set`)。

**计算公式：**
$$
\text{Jaccard}(A, B) = \frac{|A \cap B|}{|A \cup B|}
$$
- $|A \cap B|$：两份代码中**共同出现过**的独立Token的数量。
- $|A \cup B|$：两份代码中**所有出现过**的独立Token的总数量。

**擅长检测的场景：**
- **代码块乱序**：当学生将函数、类的定义顺序打乱，或者将代码块从一个地方挪到另一个地方时，Jaccard指数基本不受影响。
- **词汇借用**：能有效发现两份代码是否使用了大量相同的“词汇”（变量名、函数名、常量等），即使它们的用法和顺序完全不同。

**局限性：**

完全忽略了代码的逻辑顺序。例如，`a = b + c` 和 `b = a + c` 在它看来可能非常相似。

**给用户的UI简介：**
> **词汇重合度 (Jaccard Similarity)**：衡量两份代码使用了多少相同的“词汇”（如变量名、函数名等），不考虑代码顺序。此指标越高，说明两份代码的“用词”越相似。

---

### 2. 最长公共子序列比率 (LCS Ratio)

**核心思想：**

寻找两段Token序列中，按顺序排列的、最长的共同部分（Longest Common Subsequence）。这个指标非常重视代码的原始逻辑顺序。

**计算对象：**

两个Token列表 (Python `list`)。

**计算公式：**
$$
\text{LCS Ratio}(A, B) = \frac{2 \times \text{Length}(\text{LCS}(A, B))}{\text{Length}(A) + \text{Length}(B)}
$$
- $\text{LCS}(A, B)$：A和B的最长公共子序列。
- $\text{Length}(\cdot)$：序列的长度。

**擅长检测的场景：**
- **直接复制粘贴**：对于大段的连续代码复制，LCS能非常准确地捕捉到。
- **插入式修改**：即便抄袭者在复制的代码中间插入了一些自己的“干扰”代码，LCS依然能跳过这些干扰，找到前后连接起来的公共部分。

**局限性：**

对代码块的顺序调换非常敏感。如果将一个函数从文件末尾移到开头，LCS比率会显著下降。

**给用户的UI简介：**
> **逻辑顺序相似度 (LCS Ratio)**：衡量两份代码是否存在大量逻辑顺序相同的代码片段。此指标越高，说明一份代码很可能是从另一份直接复制并稍加修改得来的。

---

### 3. 序列匹配度 (Sequence Match Ratio)

**核心思想：**

它通过递归地寻找两个序列中最长的、连续的、完全匹配的子块来工作，衡量的是两个序列中相同部分所占的比例。

**计算对象：**

两个Token列表 (Python `list`)。

**擅长检测的场景：**
- **连续代码块的匹配**：对大段未作修改的复制粘贴非常敏感。
- **效率较高**：相比于编辑距离的纯动态规划，`SequenceMatcher` 在处理长序列时通常更快。

**局限性**

对零散、细碎的修改不如编辑距离敏感。

**给用户的UI简介：**
> **序列匹配度 (SeqMatch)**：通过寻找两份代码中最长的连续匹配块，并递归地处理剩余部分，来计算总体的匹配程度。此指标越高，说明两份代码中可以找到的相同代码片段越多、越长。


# 基于AST的查重指标介绍

---

### 1. 结构指纹相似度 (Structural Fingerprint Similarity)

**核心思想：**

这个方法的灵感来源于斯坦福的MOSS算法，用一种简化的方式实现。提取出树中**关键结构节点**，为每个结构生成一个“指纹”（一个哈希值），然后比较两份代码的“指纹库”有多相似。

**计算对象：**

两组从AST中提取的“结构指纹”集合 (Python `set`)。

**计算逻辑：**
* **遍历AST**：访问树中的每一个节点。
* **提取关键结构**：当我们遇到一个我们关心的节点类型时（例如 `ast.For`, `ast.If`, `ast.While`），我们将这个节点及其子节点进行“规范化”处理，转换成一个能代表其结构的稳定字符串。例如，一个`for`循环可以被表示为`"For(target=ID, iter=ID, body=[...])"`。
* **生成指纹**：使用一个快速的哈希算法（如MD5或SHA1）计算这个规范化字符串的哈希值，这个哈希值就是该结构的“指纹”。
* **比较指纹集**：收集两份代码所有的结构指纹，放入两个集合中，然后计算它们的**杰卡德相似度**。

**擅长检测的场景：**
* **高级结构性抄袭**：即便是学生重写了整个函数体，只要他保留了核心的`if-else`分支、循环结构，这个方法就能发现它们在结构上的相似性。
* **对代码风格不敏感**：完全忽略代码格式、变量名等表面差异。

**局限性：**

* 规范化字符串的生成方式需要精心设计，才能保证稳定性和代表性。
* 对于非常简单的代码（例如只有顺序语句），可能提取不出足够多的指纹。

**给用户的UI简介：**
> **结构指纹相似度 (AST Fingerprint)**：通过提取代码中的核心逻辑结构（如循环、判断分支等）并生成“指纹”，来比较两份代码在架构上的相似性。此指标越高，说明代码的“骨架”越相似。

---

### 2. 节点类型直方图相似度 (Node Type Histogram Similarity)

**核心思想：**

这是一种更宏观的结构比较方法。它不关心节点之间的具体关系，只关心“一份代码里，各种类型的语法结构分别出现了多少次”。它将每份代码转换成一个代表其语法构成的“直方图”向量。

**计算对象：**

两个代表节点类型计数的向量（或Python `dict`）。

**计算逻辑：**
* **遍历AST**：访问树中的每一个节点。
* **统计节点类型**：用一个字典记录下每种节点类型（`ast.Assign`, `ast.Call`, `ast.BinOp`等）出现的次数。
* **构建向量**：将两份代码的统计字典转换成两个维度相同的向量。
* **计算相似度**：使用**余弦相似度 (Cosine Similarity)** 来计算这两个向量的方向有多接近。余弦相似度非常适合比较这种“频率”类型的向量。

**擅长检测的场景：**
* **宏观风格分析**：能快速判断两份代码在整体上是否“偏好”使用相似的语法结构。例如，一个学生大量使用列表推导式，而另一个使用传统的`for`循环，这个指标就能体现出差异。
* **计算速度快**：只需遍历一次AST并进行简单的计数和向量运算。

**局限性：**
* 完全忽略了代码的逻辑和结构顺序，只关心“有什么”和“有多少”。两个逻辑完全不同但使用了相似语法元素的代码，也可能得到较高的分数。

**给用户的UI简介：**
> **语法构成相似度 (AST Histogram)**：通过统计代码中各类语法元素（赋值、函数调用、算术运算等）的使用频率，来比较两份代码在编程风格和语法构成上的相似性。
